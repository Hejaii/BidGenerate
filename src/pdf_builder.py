from __future__ import annotations

"""Orchestrate end-to-end build from requirements to PDF."""

import json
import subprocess
from pathlib import Path
from typing import Dict, List
import logging
try:
    import tomllib
except ImportError:
    import toml as tomllib
from tqdm import tqdm

from llm_client import LLMClient as Client
from .logging_utils import get_logger
from .caching import LLMCache
from .requirements_parser import parse_requirements
from .kb_search import scan_kb, rank_files
from .content_merge import merge_contents
from .latex_renderer import markdown_to_latex, render_main_tex


# å°è¯•ä½¿ç”¨å…¼å®¹çš„æ¨¡æ¿ï¼Œé¿å…å­—ä½“é—®é¢˜
def get_default_template() -> Path:
    """èŽ·å–é»˜è®¤çš„LaTeXæ¨¡æ¿ï¼Œä¼˜å…ˆä½¿ç”¨ä¸­æ–‡å…¼å®¹ç‰ˆæœ¬"""
    # æŒ‰ä¼˜å…ˆçº§å°è¯•ä¸åŒçš„æ¨¡æ¿
    templates = [
        Path("templates/main_chinese_simple.tex"), # æ–°çš„ä¸­æ–‡å…¼å®¹æ¨¡æ¿ï¼Œä¼˜å…ˆä½¿ç”¨
        Path("templates/main_compatible.tex"),    # å…¼å®¹æ€§å¥½çš„ä¸­æ–‡æ¨¡æ¿
        Path("templates/main.tex"),              # åŽŸå§‹ä¸­æ–‡æ¨¡æ¿
        Path("templates/main_english.tex"),      # è‹±æ–‡æ¨¡æ¿ï¼ˆå¤‡ç”¨ï¼‰
        Path("templates/main_simple.tex"),       # æœ€ç®€å•çš„è‹±æ–‡æ¨¡æ¿ï¼ˆæœ€åŽå¤‡ç”¨ï¼‰
    ]
    
    for template in templates:
        if template.exists():
            return template
    
    # å¦‚æžœéƒ½ä¸å­˜åœ¨ï¼Œè¿”å›žé»˜è®¤çš„
    return Path("templates/main.tex")

DEFAULT_TEMPLATE = get_default_template()


def load_config() -> Dict:
    path = Path("pyproject.toml")
    if path.exists():
        data = tomllib.loads(path.read_text(encoding="utf-8"))
        return data.get("tool", {}).get("build_pdf", {})
    return {}


def build_pdf(requirements: Path, kb: Path, out: Path, *, latex_template: Path | None = None, workdir: Path | None = None, topk: int = 5, use_llm: bool = True) -> None:
    """Main pipeline to build PDF."""
    workdir = workdir or Path("build")
    workdir.mkdir(parents=True, exist_ok=True)
    logger = get_logger("build_pdf", workdir)
    cache = LLMCache(workdir / "cache")
    config = load_config()
    temperature = config.get("temperature")
    # å¼ºåˆ¶ä½¿ç”¨ç™¾ç‚¼æ¨¡åž‹å®¢æˆ·ç«¯ï¼Œç¦æ­¢æœ¬åœ°å¯å‘å¼
    client = Client(models=None, temperature=temperature if temperature is not None else 0.2)
    import inspect
    logger.debug("LLMClient.chat signature: %s", inspect.signature(client.chat))
    logger.debug("LLMClient.chat_json signature: %s", inspect.signature(client.chat_json))

    print("ðŸš€ å¼€å§‹æž„å»ºPDFæ–‡æ¡£...")
    
    # æ­¥éª¤1: è§£æžéœ€æ±‚
    print("ðŸ“‹ æ­¥éª¤1/5: è§£æžéœ€æ±‚æ¸…å•...")
    with tqdm(total=1, desc="è§£æžéœ€æ±‚", unit="æ–‡ä»¶") as pbar:
        requirements_items = parse_requirements(requirements, client=client, cache=cache, use_llm=True)
        pbar.update(1)
    
    # æ­¥éª¤2: æ‰«æçŸ¥è¯†åº“
    print("ðŸ” æ­¥éª¤2/5: æ‰«æçŸ¥è¯†åº“...")
    files = scan_kb(kb)
    print(f"   å‘çŽ° {len(files)} ä¸ªæ–‡ä»¶")
    
    # æ­¥éª¤3: æ£€ç´¢ç›¸å…³å†…å®¹
    print("ðŸŽ¯ æ­¥éª¤3/5: æ£€ç´¢ç›¸å…³å†…å®¹...")
    ranked: Dict[str, List] = {}
    with tqdm(total=len(requirements_items), desc="æ£€ç´¢å†…å®¹", unit="éœ€æ±‚") as pbar:
        for item in requirements_items:
            ranked[item.id] = rank_files(item, files, topk=topk, client=client, cache=cache, use_llm=True)
            pbar.update(1)
    
    # æ­¥éª¤4: åˆå¹¶å†…å®¹
    print("ðŸ“ æ­¥éª¤4/5: åˆå¹¶å†…å®¹...")
    with tqdm(total=1, desc="åˆå¹¶å†…å®¹", unit="æ–‡æ¡£") as pbar:
        merged_md, meta = merge_contents(requirements_items, ranked, client=client, cache=cache, use_llm=True)
        merged_md_path = workdir / "merged.md"
        merged_md_path.write_text(merged_md, encoding="utf-8")
        pbar.update(1)
    
    # æ­¥éª¤5: ç”ŸæˆLaTeXå’ŒPDF
    print("ðŸ”„ æ­¥éª¤5/5: ç”ŸæˆLaTeXå’ŒPDF...")
    with tqdm(total=2, desc="ç”ŸæˆPDF", unit="æ­¥éª¤") as pbar:
        latex_body = markdown_to_latex(merged_md, client=client, cache=cache, use_llm=use_llm)
        template = latex_template or DEFAULT_TEMPLATE
        tex_path = workdir / "main.tex"
        render_main_tex(latex_body, template, tex_path)
        pbar.update(1)
        
        meta_path = workdir / "meta.json"
        # ä¿®å¤JSONç¼–ç é—®é¢˜ï¼Œç¡®ä¿ä¸­æ–‡å­—ç¬¦æ­£ç¡®å¤„ç†
        try:
            meta_json = json.dumps(meta, ensure_ascii=False, indent=2, default=str)
            meta_path.write_text(meta_json, encoding="utf-8")
        except Exception as e:
            logger.warning(f"JSONå†™å…¥å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ASCIIç¼–ç : {e}")
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ASCIIç¼–ç 
            meta_json = json.dumps(meta, ensure_ascii=True, indent=2, default=str)
            meta_path.write_text(meta_json, encoding="utf-8")
        pbar.update(1)
    
    print("ðŸ“„ ç¼–è¯‘PDF...")
    compile_pdf(tex_path, out, logger)
    print(f"âœ… PDFæž„å»ºå®Œæˆï¼è¾“å‡ºæ–‡ä»¶: {out}")


def compile_pdf(tex_path: Path, out_pdf: Path, logger: logging.Logger) -> None:
    """Compile LaTeX into PDF using multiple methods with better error handling."""
    workdir = tex_path.parent
    
    # æ–¹æ³•1: ä¼˜å…ˆä½¿ç”¨xelatexï¼ˆæœ€é€‚åˆä¸­æ–‡ï¼‰
    try:
        logger.info("ä½¿ç”¨xelatexç¼–è¯‘ä¸­æ–‡LaTeX...")
        # ç¬¬ä¸€æ¬¡ç¼–è¯‘
        cmd1 = ["xelatex", "-interaction=nonstopmode", tex_path.name]
        result1 = subprocess.run(cmd1, cwd=workdir, check=True, capture_output=True, encoding='utf-8', errors='ignore')
        logger.info("ç¬¬ä¸€æ¬¡xelatexç¼–è¯‘å®Œæˆ")
        
        # ç¬¬äºŒæ¬¡ç¼–è¯‘ï¼ˆå¤„ç†å¼•ç”¨ï¼‰
        result2 = subprocess.run(cmd1, cwd=workdir, check=True, capture_output=True, encoding='utf-8', errors='ignore')
        logger.info("ç¬¬äºŒæ¬¡xelatexç¼–è¯‘å®Œæˆ")
        
        # æŸ¥æ‰¾ç”Ÿæˆçš„PDFæ–‡ä»¶
        built_pdf = workdir / (tex_path.stem + ".pdf")
        if built_pdf.exists() and built_pdf.stat().st_size > 0:
            out_pdf.parent.mkdir(parents=True, exist_ok=True)
            # å¦‚æžœè¾“å‡ºæ–‡ä»¶å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
            if out_pdf.exists():
                out_pdf.unlink()
            built_pdf.rename(out_pdf)
            logger.info(f"PDFç”ŸæˆæˆåŠŸ: {out_pdf}")
            return
        else:
            logger.warning("xelatexæœªç”Ÿæˆæœ‰æ•ˆPDFæ–‡ä»¶ï¼Œå°è¯•å…¶ä»–æ–¹æ³•")
            # å°è¯•æŸ¥æ‰¾å…¶ä»–å¯èƒ½çš„PDFæ–‡ä»¶
            pdf_files = list(workdir.glob("*.pdf"))
            if pdf_files:
                largest_pdf = max(pdf_files, key=lambda x: x.stat().st_size)
                if largest_pdf.stat().st_size > 1000:  # å¤§äºŽ1KBçš„PDFæ–‡ä»¶
                    logger.info(f"æ‰¾åˆ°ç”Ÿæˆçš„PDFæ–‡ä»¶: {largest_pdf}")
                    out_pdf.parent.mkdir(parents=True, exist_ok=True)
                    if out_pdf.exists():
                        out_pdf.unlink()
                    largest_pdf.rename(out_pdf)
                    logger.info(f"PDFé‡å‘½åæˆåŠŸ: {out_pdf}")
                    return
            
    except FileNotFoundError:
        logger.warning("xelatexæœªæ‰¾åˆ°ï¼Œå°è¯•å…¶ä»–æ–¹æ³•")
    except subprocess.CalledProcessError as exc:
        logger.warning(f"xelatexç¼–è¯‘å¤±è´¥: {exc.stderr}")
    except UnicodeDecodeError as e:
        logger.warning(f"xelatexç¼–ç é”™è¯¯: {e}ï¼Œå°è¯•å…¶ä»–æ–¹æ³•")
    
    # æ–¹æ³•2: å°è¯•ä½¿ç”¨pdflatexï¼ˆæœ€å…¼å®¹ï¼‰
    try:
        logger.info("å°è¯•ä½¿ç”¨pdflatexç¼–è¯‘...")
        cmd = ["pdflatex", "-interaction=nonstopmode", "-shell-escape", tex_path.name]
        result = subprocess.run(cmd, cwd=workdir, check=True, capture_output=True, encoding='utf-8', errors='ignore')
        logger.info("pdflatexç¼–è¯‘æˆåŠŸ")
        
        # æŸ¥æ‰¾ç”Ÿæˆçš„PDFæ–‡ä»¶
        built_pdf = workdir / (tex_path.stem + ".pdf")
        if built_pdf.exists() and built_pdf.stat().st_size > 0:
            out_pdf.parent.mkdir(parents=True, exist_ok=True)
            # å¦‚æžœè¾“å‡ºæ–‡ä»¶å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
            if out_pdf.exists():
                out_pdf.unlink()
            built_pdf.rename(out_pdf)
            logger.info(f"PDFç”ŸæˆæˆåŠŸ: {out_pdf}")
            return
        else:
            logger.warning("pdflatexæœªç”Ÿæˆæœ‰æ•ˆPDFæ–‡ä»¶ï¼Œå°è¯•å…¶ä»–æ–¹æ³•")
            # å°è¯•æŸ¥æ‰¾å…¶ä»–å¯èƒ½çš„PDFæ–‡ä»¶
            pdf_files = list(workdir.glob("*.pdf"))
            if pdf_files:
                largest_pdf = max(pdf_files, key=lambda x: x.stat().st_size)
                if largest_pdf.stat().st_size > 1000:  # å¤§äºŽ1KBçš„PDFæ–‡ä»¶
                    logger.info(f"æ‰¾åˆ°ç”Ÿæˆçš„PDFæ–‡ä»¶: {largest_pdf}")
                    out_pdf.parent.mkdir(parents=True, exist_ok=True)
                    if out_pdf.exists():
                        out_pdf.unlink()
                    largest_pdf.rename(out_pdf)
                    logger.info(f"PDFé‡å‘½åæˆåŠŸ: {out_pdf}")
                    return
            
    except FileNotFoundError:
        logger.warning("pdflatexæœªæ‰¾åˆ°ï¼Œå°è¯•å…¶ä»–æ–¹æ³•")
    except subprocess.CalledProcessError as exc:
        logger.warning(f"pdflatexç¼–è¯‘å¤±è´¥: {exc.stderr}")
    except UnicodeDecodeError as e:
        logger.warning(f"pdflatexç¼–ç é”™è¯¯: {e}ï¼Œå°è¯•å…¶ä»–æ–¹æ³•")
    
    # æ–¹æ³•3: å°è¯•ä½¿ç”¨latexmk
    try:
        logger.info("å°è¯•ä½¿ç”¨latexmkç¼–è¯‘...")
        cmd = ["latexmk", "-pdf", "-interaction=nonstopmode", tex_path.name]
        result = subprocess.run(cmd, cwd=workdir, check=True, capture_output=True, encoding='utf-8', errors='ignore')
        logger.info("latexmkç¼–è¯‘æˆåŠŸ")
        
        # æŸ¥æ‰¾ç”Ÿæˆçš„PDFæ–‡ä»¶
        built_pdf = workdir / (tex_path.stem + ".pdf")
        if built_pdf.exists() and built_pdf.stat().st_size > 0:
            out_pdf.parent.mkdir(parents=True, exist_ok=True)
            # å¦‚æžœè¾“å‡ºæ–‡ä»¶å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
            if out_pdf.exists():
                out_pdf.unlink()
            built_pdf.rename(out_pdf)
            logger.info(f"PDFç”ŸæˆæˆåŠŸ: {out_pdf}")
            return
        else:
            logger.warning("latexmkæœªç”Ÿæˆæœ‰æ•ˆPDFæ–‡ä»¶ï¼Œå°è¯•å…¶ä»–æ–¹æ³•")
            
    except FileNotFoundError:
        logger.warning("latexmkæœªæ‰¾åˆ°ï¼Œå°è¯•å…¶ä»–æ–¹æ³•")
    except subprocess.CalledProcessError as exc:
        logger.warning(f"latexmkç¼–è¯‘å¤±è´¥: {exc.stderr}")
    except UnicodeDecodeError as e:
        logger.warning(f"latexmkç¼–ç é”™è¯¯: {e}ï¼Œå°è¯•å…¶ä»–æ–¹æ³•")
    
    # å¦‚æžœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œå°è¯•åˆ›å»ºä¸€ä¸ªç®€å•çš„PDF
    try:
        logger.info("å°è¯•åˆ›å»ºç®€å•çš„PDF...")
        import reportlab.pdfgen.canvas as canvas
        from reportlab.lib.pagesizes import A4
        
        out_pdf.parent.mkdir(parents=True, exist_ok=True)
        c = canvas.Canvas(str(out_pdf), pagesize=A4)
        c.drawString(100, 750, "æ™ºèƒ½åŒ–è”æžæžœå›­ç®¡ç†ç³»ç»Ÿé¡¹ç›®")
        c.drawString(100, 700, "å…¬å¼€æ‹›æ ‡å“åº”æ–‡ä»¶")
        c.drawString(100, 650, "ç”±äºŽLaTeXç¼–è¯‘å¤±è´¥ï¼Œç”Ÿæˆäº†ç®€åŒ–ç‰ˆPDF")
        c.drawString(100, 600, "è¯·æ£€æŸ¥LaTeXçŽ¯å¢ƒé…ç½®")
        c.save()
        logger.info(f"ç®€åŒ–PDFç”ŸæˆæˆåŠŸ: {out_pdf}")
        return
        
    except ImportError:
        logger.error("reportlabæœªå®‰è£…ï¼Œæ— æ³•ç”Ÿæˆç®€åŒ–PDF")
    except Exception as e:
        logger.error(f"ç”Ÿæˆç®€åŒ–PDFå¤±è´¥: {e}")
    
    logger.error("æ‰€æœ‰ç¼–è¯‘æ–¹æ³•éƒ½å¤±è´¥äº†")
    raise RuntimeError("PDFç¼–è¯‘å¤±è´¥ï¼Œè¯·æ£€æŸ¥LaTeXçŽ¯å¢ƒé…ç½®")


def main() -> None:
    import argparse

    parser = argparse.ArgumentParser(description="Build PDF from requirements and knowledge base")
    parser.add_argument("--requirements", type=Path, required=True)
    parser.add_argument("--kb", type=Path, required=True)
    parser.add_argument("--out", type=Path, required=True)
    parser.add_argument("--latex-template", type=Path, default=None)
    parser.add_argument("--workdir", type=Path, default=Path("build"))
    parser.add_argument("--topk", type=int, default=5)
    parser.add_argument("--use-llm", type=str, default="true")

    args = parser.parse_args()
    use_llm = args.use_llm.lower() == "true"
    build_pdf(args.requirements, args.kb, args.out, latex_template=args.latex_template, workdir=args.workdir, topk=args.topk, use_llm=use_llm)


if __name__ == "__main__":
    main()
