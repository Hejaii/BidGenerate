#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•ç‰ˆæœ¬çš„æ‹›æ ‡æ–‡ä»¶æ–‡æ¡£æå–å™¨
åªå¤„ç†å‰3é¡µæ¥éªŒè¯ä¿®å¤æ˜¯å¦æˆåŠŸ
"""

import json
import os
import sys
from typing import List, Dict, Any
import pdfplumber
from datetime import datetime
import time

from llm_client import LLMClient, DEFAULT_API_KEY

class TestDocumentExtractor:
    def __init__(self, llm: LLMClient | None = None):
        """åˆå§‹åŒ–æ–‡æ¡£æå–å™¨"""
        self.llm = llm or LLMClient()
        
    def extract_text_from_pdf(self, pdf_path: str, max_pages: int = 3) -> List[Dict[str, Any]]:
        """
        ä»PDFæ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹ï¼ŒæŒ‰é¡µåˆ†å‰²ï¼ˆæµ‹è¯•ç‰ˆæœ¬åªå¤„ç†å‰å‡ é¡µï¼‰
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            max_pages: æœ€å¤§å¤„ç†é¡µæ•°ï¼ˆæµ‹è¯•ç”¨ï¼‰
            
        Returns:
            åŒ…å«é¡µç å’Œæ–‡æœ¬å†…å®¹çš„å­—å…¸åˆ—è¡¨
        """
        pages_data = []
        
        try:
            with pdfplumber.open(pdf_path) as pdf:
                total_pages = min(len(pdf.pages), max_pages)
                print(f"æ­£åœ¨å¤„ç†PDFæ–‡ä»¶ï¼Œæµ‹è¯•ç‰ˆæœ¬åªå¤„ç†å‰ {total_pages} é¡µ...")
                
                for page_num in range(total_pages):
                    page = pdf.pages[page_num]
                    text = page.extract_text()
                    
                    if text and text.strip():
                        pages_data.append({
                            "page": page_num + 1,
                            "text": text.strip(),
                            "content_length": len(text)
                        })
                        
                        print(f"å·²å¤„ç†ç¬¬ {page_num + 1} é¡µ")
                            
        except Exception as e:
            print(f"PDFå¤„ç†é”™è¯¯: {e}")
            return []
            
        return pages_data
    
    def analyze_page_content(self, page_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        åˆ†æå•é¡µå†…å®¹ï¼Œè¯†åˆ«æ–‡æ¡£è¦æ±‚
        
        Args:
            page_data: é¡µé¢æ•°æ®å­—å…¸
            
        Returns:
            è¯†åˆ«å‡ºçš„æ–‡æ¡£è¦æ±‚åˆ—è¡¨
        """
        page_num = page_data["page"]
        text = page_data["text"]
        
        # æ„å»ºå‘é€ç»™é€šä¹‰åƒé—®çš„æç¤ºè¯
        prompt = f"""
è¯·ä»”ç»†åˆ†æä»¥ä¸‹æ‹›æ ‡æ–‡ä»¶é¡µé¢å†…å®¹ï¼Œè¯†åˆ«å‡ºæ‰€æœ‰è¦æ±‚æŠ•æ ‡äººæäº¤æˆ–é™„å¸¦çš„æ–‡æ¡£ã€ææ–™ã€è¯æ˜ç­‰ã€‚

é¡µé¢å†…å®¹ï¼š
{text}

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼Œå¦‚æœè¯†åˆ«åˆ°è¦æ±‚æäº¤çš„æ–‡æ¡£ï¼Œè¯·æå–ï¼š
1. æ–‡æ¡£åç§°ï¼ˆå…·ä½“è¦æäº¤ä»€ä¹ˆæ–‡ä»¶ï¼‰
2. åŸå§‹è¦æ±‚è¯­å¥ï¼ˆå®Œæ•´çš„å¥å­ï¼‰
3. æ–‡æ¡£ç±»å‹åˆ†ç±»ï¼ˆèµ„æ ¼æ–‡ä»¶/æŠ€æœ¯æ–‡ä»¶/å•†åŠ¡æ–‡ä»¶/å…¶ä»–ï¼‰

å¦‚æœé¡µé¢ä¸­æ²¡æœ‰ç›¸å…³è¦æ±‚ï¼Œè¯·è¿”å›ç©ºåˆ—è¡¨ã€‚

è¿”å›æ ¼å¼ï¼š
{{
    "documents": [
        {{
            "name": "æ–‡æ¡£åç§°",
            "original_text": "åŸå§‹è¦æ±‚è¯­å¥",
            "category": "æ–‡æ¡£ç±»å‹åˆ†ç±»"
        }}
    ]
}}

è¯·ç¡®ä¿è¿”å›çš„æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚
"""
        
        messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ‹›æ ‡æ–‡ä»¶åˆ†æä¸“å®¶ï¼Œæ“…é•¿è¯†åˆ«å’Œæå–æ‹›æ ‡æ–‡ä»¶ä¸­è¦æ±‚æŠ•æ ‡äººæäº¤çš„å„ç§æ–‡æ¡£å’Œææ–™ã€‚",
            },
            {"role": "user", "content": prompt},
        ]

        try:
            print(f"æ­£åœ¨è°ƒç”¨é€šä¹‰åƒé—®APIåˆ†æç¬¬ {page_num} é¡µ...")
            api_response = self.llm.chat_json(messages)
            print(f"ç¬¬ {page_num} é¡µAPIè°ƒç”¨æˆåŠŸ")
            return api_response.get("documents", [])
        except Exception as e:
            print(f"ç¬¬ {page_num} é¡µAPIè°ƒç”¨å¤±è´¥: {e}")
            return []
    
    def test_extraction(self, pdf_path: str) -> List[Dict[str, Any]]:
        """
        æµ‹è¯•æ–‡æ¡£æå–åŠŸèƒ½
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            
        Returns:
            æå–çš„æ–‡æ¡£åˆ—è¡¨
        """
        print("å¼€å§‹æµ‹è¯•PDFæ–‡æœ¬å†…å®¹æå–...")
        pages_data = self.extract_text_from_pdf(pdf_path, max_pages=3)
        
        if not pages_data:
            print("PDFæ–‡æœ¬æå–å¤±è´¥")
            return []
        
        print(f"æ–‡æœ¬æå–å®Œæˆï¼Œå…± {len(pages_data)} é¡µ")
        print("å¼€å§‹ä½¿ç”¨é€šä¹‰åƒé—®APIåˆ†ææ¯é¡µå†…å®¹...")
        
        all_documents = []
        
        for i, page_data in enumerate(pages_data):
            print(f"æ­£åœ¨åˆ†æç¬¬ {page_data['page']} é¡µ ({i+1}/{len(pages_data)})...")
            
            documents = self.analyze_page_content(page_data)
            if documents:
                all_documents.extend(documents)
                print(f"ç¬¬ {page_data['page']} é¡µè¯†åˆ«åˆ° {len(documents)} ä¸ªæ–‡æ¡£è¦æ±‚")
            else:
                print(f"ç¬¬ {page_data['page']} é¡µæœªè¯†åˆ«åˆ°æ–‡æ¡£è¦æ±‚")
            
            # æ·»åŠ å»¶è¿Ÿé¿å…APIé™æµ
            time.sleep(1)
        
        return all_documents

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ æµ‹è¯•ç‰ˆæ‹›æ ‡æ–‡ä»¶æ–‡æ¡£æå–å™¨")
    print("=" * 50)
    
    # æ£€æŸ¥APIå¯†é’¥
    api_key = os.getenv("QIANWEN_API_KEY", DEFAULT_API_KEY)
    llm = LLMClient(api_key=api_key)
    
    # æ£€æŸ¥PDFæ–‡ä»¶
    pdf_path = "03.æ‹›æ ‡æ–‡ä»¶.pdf"
    if not os.path.exists(pdf_path):
        print(f"âŒ é”™è¯¯ï¼šPDFæ–‡ä»¶ä¸å­˜åœ¨ï¼š{pdf_path}")
        sys.exit(1)
    
    # åˆ›å»ºæå–å™¨
    extractor = TestDocumentExtractor(llm)
    
    try:
        # æµ‹è¯•æå–åŠŸèƒ½
        print("ğŸš€ å¼€å§‹æµ‹è¯•æ–‡æ¡£æå–åŠŸèƒ½...")
        documents = extractor.test_extraction(pdf_path)
        
        if not documents:
            print("âš ï¸ æœªè¯†åˆ«åˆ°ä»»ä½•æ–‡æ¡£è¦æ±‚")
        else:
            print(f"âœ… æµ‹è¯•å®Œæˆï¼Œå…±è¯†åˆ«åˆ° {len(documents)} é¡¹è¦æ±‚")
            for doc in documents:
                print(f"  - {doc['name']} ({doc['category']})")
        
        print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()

